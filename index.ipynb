{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **概要**\n",
    "\n",
    "AlphaZeroのアルゴリズムは以下のような手順で構成される：\n",
    "\n",
    "1. 自己対戦による学習: AlphaZeroは、自分自身と対戦しながら学習する。ランダムな手法からスタートし、強化学習アルゴリズムを用いて次第に強くなる。\n",
    "\n",
    "2. モンテカルロ木探索: AlphaZeroは、モンテカルロ木探索（MCTS）を使用してゲームのツリーを探索する。これにより、最適な手を見つけるために局面を評価し、次の手を決定する。\n",
    "\n",
    "3. ニューラルネットワーク: AlphaZeroは、ゲームの状態を評価するためのニューラルネットワークを使用する。このニューラルネットワークは、ゲームの局面を入力とし、局面の価値を出力する。価値は、勝率や局面の良さなどを示す。\n",
    "\n",
    "4. 強化学習: AlphaZeroは、報酬を最大化するようにニューラルネットワークを調整することで学習します。報酬は、ゲームの勝利や敗北などによって与えられます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **オセロのルールを反映させたクラス**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# オセロの状態を表すクラス(構造体)\n",
    "# 8x8の盤面を持ち、各マスには黒か白か空かのいずれかが入る\n",
    "# 盤面の状態を配列で表現する\n",
    "class Board():\n",
    "    # 8x8の配列を初期化する\n",
    "    def __init__(self):\n",
    "        self.board = [[0 for i in range(8)] for j in range(8)]\n",
    "        self.board[3][3] = 1    # 白(◯)\n",
    "        self.board[4][4] = 1    # 白\n",
    "        self.board[3][4] = -1    # 黒(×)\n",
    "        self.board[4][3] = -1    # 黒\n",
    "        self.player = -1         # 黒が先手\n",
    "    # 盤面の配列を取得する\n",
    "    def getBoard(self):\n",
    "        return self.board\n",
    "    # 盤面の状態を表示する\n",
    "    def show(self):\n",
    "        for row in self.board:\n",
    "            print(\"|\", end=\"\")\n",
    "            for cell in row:\n",
    "                if cell == 0:\n",
    "                    print(\" \", end=\"\")  # end=\"\" で改行しない\n",
    "                elif cell == 1:\n",
    "                    print(\"o\", end=\"\")\n",
    "                elif cell == -1:\n",
    "                    print(\"x\", end=\"\")\n",
    "            print(\"|\")                     # 一行表示して改行\n",
    "        print(\"player: o\") if self.player == 1 else print(\"player: x\")\n",
    "    # ファイルに盤面の状態を書き込む\n",
    "    def fshow(self, filename):\n",
    "        with open(filename, \"w\") as f:\n",
    "            for row in self.board:\n",
    "                f.write(\"|\")\n",
    "                for cell in row:\n",
    "                    if cell == 0:\n",
    "                        f.write(\" \")\n",
    "                    elif cell == 1:\n",
    "                        f.write(\"o\")\n",
    "                    elif cell == -1:\n",
    "                        f.write(\"x\")\n",
    "                    f.write(str(cell))\n",
    "                f.write(\"|\\n\")\n",
    "            if self.player == 1:\n",
    "                f.write(\"player: o\")\n",
    "            else:\n",
    "                f.write(\"player: x\")\n",
    "    # 置く場所が盤面上にあるか判定する\n",
    "    def outofBoard(self, x, y):\n",
    "        return x < 0 or x >= 8 or y < 0 or y >= 8\n",
    "    # (x, y)に石を置くとき、(dx, dy)方向にひっくり返す石があるか判定する\n",
    "    def canPutDir(self, x, y, dx, dy):\n",
    "        i = 1\n",
    "        if self.outofBoard(x + dx, y + dy):\n",
    "            return False\n",
    "        else:\n",
    "            while self.board[y + dy * i][x + dx * i] == -(self.player):    # 相手の石が続く限り\n",
    "                i += 1\n",
    "                if self.outofBoard(x + dx * i, y + dy * i):                 # 盤面外に出たら\n",
    "                    return False\n",
    "                elif self.board[y + dy * i][x + dx * i] == 0:               # 石がない場所があれば\n",
    "                    return False\n",
    "                elif self.board[y + dy * i][x + dx * i] == self.player:     # 自分の石で挟めるなら\n",
    "                    return True\n",
    "    # (x, y)に石を置けるか判定する\n",
    "    def canPut(self, x, y):\n",
    "        if not self.outofBoard(x,y) and self.board[y][x] != 0:                                           # すでに石が置かれている\n",
    "            return False\n",
    "        # 周囲8方向を調べる; 1方向でもひっくり返せるなら置ける\n",
    "        for dx in range(-1, 2):\n",
    "            for dy in range(-1, 2):\n",
    "                if dx == 0 and dy == 0: \n",
    "                    continue\n",
    "                if self.canPutDir(x, y, dx, dy):                             # (dx, dy)方向にひっくり返せる石がある\n",
    "                    return True\n",
    "        return False\n",
    "    # (x, y)に石を置いたときの盤面クラスを返す\n",
    "    def put(self, x, y):\n",
    "        newBoard = Board()\n",
    "        newBoard.board = [row[:] for row in self.board] # 盤面をコピー\n",
    "        newBoard.player = -self.player   # プレイヤーを交代\n",
    "        newBoard.board[y][x] = self.player  # 石を置く\n",
    "        # ひっくり返せる石を全てひっくり返す\n",
    "        for dx in range(-1, 2):\n",
    "            for dy in range(-1, 2):\n",
    "                if dx == 0 and dy == 0:\n",
    "                    continue\n",
    "                if self.canPutDir(x, y, dx, dy):\n",
    "                    i = 1\n",
    "                    while newBoard.board[y + dy * i][x + dx * i] == -self.player:\n",
    "                        newBoard.board[y + dy * i][x + dx * i] = self.player    # 石をひっくり返す\n",
    "                        i += 1\n",
    "        return newBoard\n",
    "    # 石を置ける場所があるか判定する\n",
    "    def canPlay(self):\n",
    "        for y in range(8):\n",
    "            for x in range(8):\n",
    "                if self.canPut(x, y):\n",
    "                    return True\n",
    "        return False\n",
    "    # 石を置ける場所と置いた場合の盤面クラスを辞書型で返す\n",
    "    def choices(self):          # 動的計画法において、for choice in board.choices(): で呼び出す\n",
    "        choices = {}\n",
    "        for y in range(8):\n",
    "            for x in range(8):\n",
    "                if self.canPut(x, y):\n",
    "                    choices[(x, y)] = self.put(x, y)\n",
    "        return choices\n",
    "    # 石を置ける場所がなく場合にプレイヤーを交代するか判定し、交代する (交代する場合は新たな盤面を返す)\n",
    "    def passPlayer(self):   # Board.passPlayer()で呼び出す\n",
    "        if not self.canPlay():\n",
    "            # 新たな盤面を作成し、プレイヤーを交代する\n",
    "            newBoard = Board()\n",
    "            newBoard.board = [row[:] for row in self.board] # 盤面をコピー\n",
    "            newBoard.player = -self.player\n",
    "            return newBoard\n",
    "    # 勝負がついたか判定する\n",
    "    def isEnd(self):\n",
    "        if not self.canPlay() and not self.passPlayer().canPlay():\n",
    "            print(\"Game Over\")\n",
    "            self.winner()\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    # 石の数を数え、勝敗を判定する\n",
    "    def count(self):\n",
    "        black = 0\n",
    "        white = 0\n",
    "        for row in self.board:\n",
    "            for cell in row:\n",
    "                if cell == 1:\n",
    "                    white += 1\n",
    "                elif cell == -1:\n",
    "                    black += 1\n",
    "        return black, white\n",
    "    def winner(self):\n",
    "        if self.isEnd() == False:\n",
    "            return\n",
    "        black = self.board.count(-1)\n",
    "        white = self.board.count(1)\n",
    "        if black > white:\n",
    "            print(\"Black(×) wins!\")\n",
    "            return 1\n",
    "        elif black < white:\n",
    "            print(\"White(◯) wins!\")\n",
    "            return -1\n",
    "        else:\n",
    "            print(\"Draw\")\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **実際にプレイしてみる**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|        |\n",
      "|        |\n",
      "|        |\n",
      "|   ox   |\n",
      "|   xo   |\n",
      "|        |\n",
      "|        |\n",
      "|        |\n",
      "player: x\n",
      "Put coordinate x, y: "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m board\u001b[38;5;241m.\u001b[39mcanPlay():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPut coordinate x, y: \u001b[39m\u001b[38;5;124m\"\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28minput\u001b[39m()\u001b[38;5;241m.\u001b[39msplit())                \u001b[38;5;66;03m# 入力を受け取る\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;124m\"\u001b[39m, x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m, y,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)                      \u001b[38;5;66;03m# 入力を表示\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m board\u001b[38;5;241m.\u001b[39mcanPut(x, y):\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 0)"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# ゲームをプレイする\n",
    "board = Board()\n",
    "while not board.isEnd():\n",
    "    time.sleep(1.0)                                     # 0.5秒待つ\n",
    "    clear_output()                                      # 画面をクリア\n",
    "    board.show()                                        # 盤面を表示\n",
    "    if board.canPlay():\n",
    "        print(\"Put coordinate x, y: \", end=\"\")\n",
    "        x, y = map(int, input().split())                # 入力を受け取る\n",
    "        print(\"(\", x, \", \", y,\")\")                      # 入力を表示\n",
    "        if board.canPut(x, y):\n",
    "            board = board.put(x, y)\n",
    "        else:\n",
    "            print(\"Can't put\")\n",
    "    else:\n",
    "        board = board.passPlayer()                      # 石を置けない場合はプレイヤーを交代"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **探索アルゴリズム**\n",
    "\n",
    "**Monte-Carlo-Tree-Search(MCTS)**による学習アルゴリズムを実装する。\n",
    "\n",
    "### **MCTSのアルゴリズム**\n",
    "\n",
    "参考文献：[Monte Carlo Tree Search - Wikipedia](https://en.wikipedia.org/wiki/Monte_Carlo_tree_search)\n",
    "\n",
    "モンテカルロ木探索は4つのステップからなる。\n",
    "\n",
    "Nodeは、ゲームの状態を表し、プレイアウトの回数と勝利の回数を保持している。\n",
    "\n",
    "1. 選択：Root Node から始めて、Leaf Node にたどり着くまで、子ノードを選択し続ける。Root Node が現在のゲームの状態で、Leaf Node はシミュレーションが行われていないノード。より有望な方向に木が展開していくように、子ノードの選択を片寄らせる方法を採用するため、以下の Alpha Zero 指標を用いる。\n",
    "2. 展開：Leaf Node が勝負を決するノードでない限り、Leaf Node から有効手の子ノードの中から Child Node を1つ選ぶ。\n",
    "3. シミュレーション：Child Node からプレイアウトを行う。Alpha Zero 指標に基づいてプレイアウトを実行する。\n",
    "4. バックプロパゲーション：Child Node から Root Node へのパスに沿って、プレイアウトの結果を伝搬する。\n",
    "\n",
    "### **Alpha Zero 指標**\n",
    "\n",
    "Alpha Zero 指標は、探索と活用のバランスを取る指標である。\n",
    "\n",
    "$ Q(s, a) + U(s, a) $\n",
    "\n",
    "が最大となる行動を選択する。ここで、$Q(s, a)$ は状態 $s$ で行動 $a$ を取った時の行動価値関数 $(=V(s'))$、$U(s, a)$ は探索項である。\n",
    "\n",
    "$ U(s, a) = c(s) P(s, a) \\frac{\\sqrt{\\sum_{b} N(s, b)}}{1 + N(s, a)} $\n",
    "\n",
    "ここで、$c(s)$ は下記の式で定まる数で、$P(s, a)$ は方策ネットワークによる行動 $a$ の選択確率、$N(s, a)$ は状態 $s$ で行動 $a$ を選択した回数、$\\sum_{b} N(s, b)$ は状態 $s$ に到達した回数である。\n",
    "\n",
    "$ c(s) = c_{init} + \\log{\\frac{1 + N(s) + c_{base}}{c_{base}}} $\n",
    "\n",
    "ここで、$c_{base}$ はハイパーパラメータであり、$N(s)$ は状態 $s$ に到達した回数である。\n",
    "\n",
    "### **Q関数の更新**\n",
    "\n",
    "チェスは、遷移確率が one-hot つまり $P(s'|s,a)=1$ であるため、状態価値関数 $V(s)$ と行動価値関数 $Q(s, a)$ は同じものとして扱うことができる。したがって、\n",
    "盤面の状態を64次元のベクトル(とる値は ${-1,0,1}$ )で表現し、それに対して有利不利を $[-1,1]$ の範囲で出力する状態行動価値関数 $Q(s,a)=V(s')$ を学習する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte-Carlo Tree のノードを表すクラス\n",
    "class MCTSNode:\n",
    "    def __init__(self, board):\n",
    "        self.board = board          # Boardクラス\n",
    "        self.parent = None          # 親ノード\n",
    "        self.children = []          # 子ノード\n",
    "        self.visits = 0             # ノードを訪れた回数\n",
    "        self.score = 0              # ノードの評価値\n",
    "    # ノードの展開(子ノードを追加)\n",
    "    def expand(self):\n",
    "        if self.board.isEnd():          # ゲーム終了時は展開しない\n",
    "            return\n",
    "        elif len(self.children) > 0:    # 既に展開済みの場合は展開しない\n",
    "            return\n",
    "        else:\n",
    "            choices = self.board.choices()              # 石を置ける場所と置いた場合の盤面クラスを取得(Boardクラスのchoicesメソッド)\n",
    "            for choice, board in choices.items():       # 石を置ける場所全てについて、子ノードに追加\n",
    "                node = MCTSNode(board)\n",
    "                node.parent = self\n",
    "                self.children.append(node)\n",
    "    # 子ノードの選択確率を計算し、石を置いた場所にその確率を当てはめた二次元配列を返す\n",
    "    def probabilities(self):\n",
    "        probs = [[0 for i in range(8)] for j in range(8)]\n",
    "        for child in self.children:\n",
    "            x, y = child.board.choices()    # 石を置いた場所を取得\n",
    "            probs[y][x] = child.visits/self.visits    # 確率を計算\n",
    "        # 確率の合計がほぼ1であることを確認し、あまりにも差がある場合には、エラーを出力\n",
    "        if abs(sum([sum(prob) for prob in probs]) - 1) > 0.01:\n",
    "            print(\"Error: sum(prob) != 1\")\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# mctsNodeで、choiceを選択することの評価値(行動価値関数と探索項の和)を返す\n",
    "def alpha_zero_score(mctsNode, key, mcTree, Policy):\n",
    "    # ハイパーパラメータ\n",
    "    c_base = 1000\n",
    "    c_init = 1.25\n",
    "    # 行動価値関数\n",
    "    value = 0                           # 0を行動価値関数Q(mctsNode.board, choice)に置き換える\n",
    "    # ノードの探索項を計算\n",
    "    N = mctsNode.visits                                 # mctsNodeを訪れた回数\n",
    "    childNode = mcTree.move_cop(key)                    # keyの手を打ったときのノードを取得\n",
    "    Nc = childNode.visits                               # mctsNodeからchoiceを選択した回数\n",
    "    C = c_init + np.log((N + c_base + 1) / c_base)      # ノードの訪問回数で決まる係数\n",
    "    exploration = C * np.sqrt(N) / (1 + Nc) * Policy(mctsNode.board, key)          # 探索項\n",
    "    # ノードの評価値と探索項の和を返す\n",
    "    return value + exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Monte-Carlo Tree のクラス\n",
    "class MCTree:\n",
    "    def __init__(self, board):\n",
    "        self.root = MCTSNode(board)                 # ルートノードを作成\n",
    "        self.current = self.root                    # 現在のノード\n",
    "    # ノードの選択\n",
    "    def select(self, Policy):\n",
    "        node = self.root\n",
    "        choices = self.current.board.choices()              # 石を置ける場所と置いた場合の盤面を取得\n",
    "        # alpha_zero_score()を用いて、評価値が最大の子ノードを選択\n",
    "        max_score = -math.inf\n",
    "        for choice, board in choices.items():\n",
    "            for child in node.children:\n",
    "                if child.board == board:\n",
    "                    score = alpha_zero_score(node, choice, self, Policy)\n",
    "                    if score > max_score:\n",
    "                        max_score = score\n",
    "                        node = child\n",
    "        return node\n",
    "    # ノードの移動(クラスをコピーせず、現在のノードを変更する)\n",
    "    def move_cur(self, key):                        # key: 石を置く場所を指定\n",
    "        # 現在のノードに対して、keyに石を置いた場合の盤面を辞書のキーから検索\n",
    "        choices = self.current.board.choices()              # 石を置ける場所と置いた場合の盤面を取得\n",
    "        for choice, board in choices.items():\n",
    "            if choice == key:                               # keyに石を置いた場合の盤面クラスを子ノードから見つけたら\n",
    "                for child in self.current.children:\n",
    "                    if child.board == board:                # 盤面クラスの一致を確認\n",
    "                        self.current = child\n",
    "                        self.path.append(child)\n",
    "                        return\n",
    "    # ノードの移動(クラスをコピーして、現在のノードを変更する)\n",
    "    def move_cop(self, key):                       # key: 石を置く場所を指定\n",
    "        # 現在のノードに対して、keyに石を置いた場合の盤面を辞書のキーから検索\n",
    "        choices = self.current.board.choices()              # 石を置ける場所と置いた場合の盤面を取得\n",
    "        for choice, board in choices.items():\n",
    "            if choice == key:                               # keyに石を置いた場合の盤面クラスを子ノードから見つけたら\n",
    "                for child in self.current.children:\n",
    "                    if child.board == board:                # 盤面クラスの一致を確認\n",
    "                        self.current = child\n",
    "                        self.path.append(child)\n",
    "                        return child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **自己対戦クラスの実装**\n",
    "\n",
    "プレイヤークラスのメソッドは以下の通りです。\n",
    "\n",
    "#### **MC Tree の初期化**\n",
    "\n",
    "#### **経験の獲得**\n",
    "\n",
    "今回は、行動毎に報酬を得るわけではなく、１ゲームをプレーした後に報酬を得ることに注意が必要である。さらには、バッチサイズ分ゲームをプレーして、それに対する\n",
    "\n",
    "#### **MC Tree の更新**\n",
    "\n",
    "実際のプレイヤーの行動とそれに対する報酬(勝利:1, 敗北:-1, 引き分け:0)を受け取り、MC Tree に追加します。\n",
    "\n",
    "#### **状態行動価値関数の初期化**\n",
    "\n",
    "状態行動価値関数 $Q_{\\theta}(s_t, a_t)$ について、初期化する。\n",
    "\n",
    "#### **方策の更新**\n",
    "\n",
    "基本的には、マルチステップ方策評価・マルチステップ方策更新を行う。その際には、Greedy Policy とするか、$\\epsilon$-Greedy Policy 、あるいは Softmax Policy とするかを指定する。\n",
    "\n",
    "#### **行動の選択**\n",
    "自分のターンが来たら、方策に従って行動を選択する。決定論的な方策を取るか、確率的な方策を取るかは、方策の種類次第になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, Policy):\n",
    "        self.Policy = Policy            # 方策NN            \n",
    "        self.path = [[]]                # プレイしたノード(MCTSNodeクラス)の履歴\n",
    "        self.nodes = []                 # ミニバッチ全体で一度でもプレイしたノード(MCTSNodeクラス)のリスト\n",
    "        self.cursor = 0                 # ミニバッチにおける現在のインデックス\n",
    "        self.reward = [0,0]             # [黒の報酬、白の報酬](勝利: 1, 引き分け: 0.5, 敗北: 0)\n",
    "    # 1手プレイする\n",
    "    def oneplay(self, mctree, filename):\n",
    "        # モンテカルロ木探索\n",
    "        if len(mctree.current.children)==0:             # 子ノードがない場合は展開\n",
    "            mctree.current.expand()\n",
    "        mctree.current = mctree.select(self.Policy)     # ノードの選択と現ノードの変更\n",
    "        self.path[self.cursor].append(mctree.current)                # 選択したノードを記録\n",
    "        # self.nodesに進んだ先のノードがなければ追加\n",
    "        if mctree.current not in self.nodes:\n",
    "            self.nodes.append(mctree.current)\n",
    "        # 盤面をファイルに書き込む\n",
    "        mctree.current.board.fshow(filename)\n",
    "    # 1ゲーム自己対戦する\n",
    "    def play1game(self, mctree):\n",
    "        board = Board()\n",
    "        while not board.isEnd():\n",
    "            self.oneplay(mctree)\n",
    "        if board.winner() == 1:\n",
    "            self.reward[0] += 1\n",
    "        elif board.winner() == -1:\n",
    "            self.reward[1] += 1\n",
    "        else:\n",
    "            self.reward[0] += 0.5\n",
    "            self.reward[1] += 0.5\n",
    "    # プレイしたノードの訪問回数と評価値を更新する\n",
    "    def backup(self):\n",
    "        for node in self.path[self.cursor]:                  # プレイしたノード全てについて\n",
    "            node.visits += 1\n",
    "            if node.board.player == 1:          # そのノードでプレイしたのが黒の場合\n",
    "                node.score += self.reward[0]\n",
    "            else:                               # そのノードでプレイしたのが白の場合\n",
    "                node.score += self.reward[1]\n",
    "    # モンテカルロ・シミュレーションのサンプルサイズ分、1ゲーム自己対戦・backupする\n",
    "    def play1batch(self, mctree, sample_size):\n",
    "        for i in range(sample_size):\n",
    "            self.play1game(mctree)\n",
    "            self.backup()\n",
    "            if i != sample_size - 1:\n",
    "                self.cursor += 1\n",
    "                self.path.append([])\n",
    "    # self.nodesを、visit回数の降順にソートする\n",
    "    def sort_nodes(self):\n",
    "        self.nodes.sort(key=lambda x: x.visits, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **方策ネットワーククラスの実装**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorchのライブラリをインポート\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "\n",
    "trans = torchvision.transforms.ToTensor()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "class p_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()  # 親クラスのnn.Moduleを呼び出し\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size=5, padding=2, padding_mode='replicate'),    # out_channelsは欲しい特徴マップの数\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 16, kernel_size=5, padding=2, padding_mode='replicate'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1, padding_mode='replicate'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 4, kernel_size=3, padding=1, padding_mode='replicate'),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 1, kernel_size=1),\n",
    "            nn.Softmax(dim=1)               # 確率分布に変換\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(64, 64),              # 全結合層\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "        )\n",
    "    # データの準備\n",
    "    def prepare(self, nodes):\n",
    "        # ミニバッチのデータを作成\n",
    "        x = []  # 盤面の状態(入力)\n",
    "        y = []  # 方策(出力)\n",
    "        for node in nodes:\n",
    "            x_item = node.board.getBoard()\n",
    "            # 盤面の状態をndarray型に変換し、全ての要素を+1して、float型に変換\n",
    "            x_item = np.array(x_item)           # ndarray型に変換\n",
    "            if node.board.player == -1:\n",
    "                x_item = x_item * -1\n",
    "            x_item = x_item + 1\n",
    "            x_item.tolist()                     # リストに変換\n",
    "            x.append(x_item)\n",
    "            # 教師信号は、mcTreeにおいて、選択されたノードに対する、子ノードの選択確率(ここでは、石を置いた場所に確率を割り当てる)\n",
    "            y.append(node.probabilities())\n",
    "        x = np.array(x)\n",
    "        # 方策をndarray型に変換\n",
    "        y = np.array(y)\n",
    "        # ミニバッチのデータをpytorchのテンソルに変換\n",
    "        input = trans(x)\n",
    "        target = trans(y)\n",
    "        # モデル、オプティマイザ、エポック数、バッチサイズを設定\n",
    "        optimizer = optim.Adam(self.parameters(), lr = 0.001, weight_decay = 5e-4)\n",
    "        num_epochs = 10\n",
    "        return input, target, optimizer, num_epochs\n",
    "    # 盤面の状態を入力として、方策を返す\n",
    "    def forward(self, input):\n",
    "        hidden = self.features(input)\n",
    "        hidden = hidden.view(hidden.size(0),-1)  # x.size(0)は例えばnum_batches\n",
    "        output = self.classifier(hidden)\n",
    "        return output\n",
    "    # 実際の石の置き場所と方策との交差エントロピー誤差を損失関数とする\n",
    "    def backprop(self, output, optimizer, criterion, target):\n",
    "        loss = criterion(output,target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # return loss(output, target)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **学習の一例**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = p_net()             # 方策NNを作成\n",
    "batch_size = 64             # バッチサイズ\n",
    "sample_size = 2000          # サンプルサイズ(モンテカルロ・シミュレーションで確率分布を求めるためのサンプル数)  *スケジューリングで変更したい\n",
    "board = Board()             # 盤面を初期化\n",
    "mctree = MCTree(board)      # モンテカルロ探索木を初期化\n",
    "# 自己対戦プレイヤーを作成\n",
    "player = Player(model)      \n",
    "player.play1batch(mctree, sample_size)  # サンプルサイズ分、自己対戦を行い、学習する\n",
    "player.sort_nodes()         # プレイしたノードを訪問回数の降順にソート\n",
    "# player.nodesをミニバッチに分割\n",
    "cursor = len(player.nodes)\n",
    "node_groups = []\n",
    "while cursor > batch_size:\n",
    "    cursor -= batch_size\n",
    "    nodes = player.nodes[cursor:cursor+batch_size]\n",
    "    node_groups.append(nodes)\n",
    "for nodes in node_groups:\n",
    "    input, target, optimizer, num_epochs = model.prepare(nodes)\n",
    "    output = model.forward(input)\n",
    "    model.backprop(output, optimizer, criterion, target)\n",
    "    \n",
    "\n",
    "# input, target をミニバッチに分割"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **価値ネットワーククラスの実装**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
